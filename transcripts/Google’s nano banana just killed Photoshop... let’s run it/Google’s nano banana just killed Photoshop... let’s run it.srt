1
00:00:00,000 --> 00:00:05,440
A few days ago, image editing changed forever. Google released Gemini Flash 2.5 image,

2
00:00:05,540 --> 00:00:08,460
coincidentally with the same nickname my ex-girlfriend gave me,

3
00:00:08,640 --> 00:00:13,740
Nano Banana. That has everyone buying puts on Adobe, because Photoshop is officially dead.

4
00:00:13,860 --> 00:00:18,020
Instead of learning how to use all these antique tools, you can now just prompt Nano Banana for

5
00:00:18,020 --> 00:00:22,660
changes and it's able to deliver any photo alterations you can imagine. And most importantly,

6
00:00:22,920 --> 00:00:27,420
while maintaining the consistency of the original image. If you're an animator or graphic designer,

7
00:00:27,420 --> 00:00:32,120
this can unlock massive productivity gains. Like if you wanted to steal some meat canyon art and

8
00:00:32,120 --> 00:00:36,400
make it do something else, you can now accomplish that with a single prompt. No talent necessary.

9
00:00:36,680 --> 00:00:41,240
Google is finally back to its roots building cool stuff, and Flash 2.5 is a tool that makes

10
00:00:41,240 --> 00:00:45,400
stable diffusion look like Microsoft Paint. In today's video, we'll take a look at all of its

11
00:00:45,400 --> 00:00:50,700
capabilities and find out if our Adobe puts will actually print. It is August 29th, 2025,

12
00:00:51,160 --> 00:00:55,420
and you're watching The Code Report. Not only is Nano Banana an exceptional image model that's

13
00:00:55,420 --> 00:00:57,400
already at the top of the LM Arena leaderboard, but it's also a great way to get your image

14
00:00:57,400 --> 00:01:03,220
but it's also extremely fast and affordable, costing only 3.9 cents per image via the API.

15
00:01:03,480 --> 00:01:08,420
And hypothetically, Google has also trained an even more powerful Grande Banana, but it's unlikely

16
00:01:08,420 --> 00:01:12,420
the common man will ever get access to it. The upgrade that most people are talking about though

17
00:01:12,420 --> 00:01:17,500
is character consistency. If you start with an image of a person or pet for example, the model

18
00:01:17,500 --> 00:01:22,020
can blend it with a different image or make minor changes to it without noticeably altering the

19
00:01:22,020 --> 00:01:26,720
original character. Or multiple characters and objects like this guy did by blending 13 different

20
00:01:26,720 --> 00:01:27,380
images together. If you're an animator or graphic designer, you can also use Nano Banana to

21
00:01:27,400 --> 00:01:29,620
create a character that looks like a human. That means if you want a LinkedIn headshot of yourself

22
00:01:29,620 --> 00:01:34,060
wearing a nice suit, but can't afford to buy an actual suit, Nano Banana has you covered.

23
00:01:34,060 --> 00:01:38,460
In addition, if you work for the Shadow government, it can be used to implement Mandela effects,

24
00:01:38,460 --> 00:01:42,660
like removing the cornucopia from the Fruit of the Loom logo. That's cool, but if you're a wannabe

25
00:01:42,660 --> 00:01:46,780
game developer, one of the main showstoppers is the insane amount of time it takes to build up a

26
00:01:46,780 --> 00:01:51,220
collection of good looking assets for all your characters and animations. Well now, if you start

27
00:01:51,220 --> 00:01:55,540
with a base character, you can prompt all the different positions required for an animation.

28
00:01:55,540 --> 00:01:56,500
Or better yet, just have Gemini, the main character, and the main character in the game. You can

29
00:01:56,500 --> 00:01:57,020
create a character that looks like a human, or a character that looks like a human, or a character that

30
00:01:57,020 --> 00:01:57,740
looks like a human, or a character that looks like a human. And you can also have Gemini generate

31
00:01:57,740 --> 00:02:01,900
an entire sprite for you with all of them in a single prompt. Keep in mind though, if you go this

32
00:02:01,900 --> 00:02:06,860
route, you'll have to disclose any AI assets used when you publish on Steam. And you can't lie about

33
00:02:06,860 --> 00:02:11,500
it, because anything generated with Google has an invisible watermark called SynthID. What's kind of

34
00:02:11,500 --> 00:02:15,980
crazy about this model though, is that it also has an understanding of the real world. Like if you

35
00:02:15,980 --> 00:02:20,300
point to a spot on Google Maps and ask what a person would see there, it can generate a realistic

36
00:02:20,300 --> 00:02:24,060
photo. Or if you're a visual learner, you can sketch with it step by step. Like you could use

37
00:02:24,060 --> 00:02:26,840
the Sketch tool to map out your AWS infrastructure. And it's a great way to get the most out of your

38
00:02:26,840 --> 00:02:31,400
It's also pretty decent at handling text, so you can easily turn your images into lame Instagram

39
00:02:31,400 --> 00:02:36,000
ads or memes. But it's still not perfect, so now let's talk about the bad stuff. As you can see in

40
00:02:36,000 --> 00:02:41,060
my ad here, it has a tendency to add extra characters to certain words. In addition, I found

41
00:02:41,060 --> 00:02:45,520
that it often didn't follow my prompt exactly and just kind of did its own thing. Or in many cases,

42
00:02:45,600 --> 00:02:49,760
it just ignored the prompt and did nothing at all. And I think even the character consistency is a

43
00:02:49,760 --> 00:02:54,020
bit overhyped. I tried it on a bunch of different images of real humans, and it still has that

44
00:02:54,020 --> 00:02:56,820
obvious AI uncanny valley look to it. And finally, I found that it's a little bit more

45
00:02:56,820 --> 00:03:01,040
as expected as a Google product, it's highly censored. Trying to generate anything that's

46
00:03:01,040 --> 00:03:05,920
not safe for work is not going to happen. But the best way to get the most out of these AI tools is

47
00:03:05,920 --> 00:03:10,220
to learn how they work under the hood. And you can do that for free with Brilliant, the sponsor of

48
00:03:10,220 --> 00:03:15,060
today's video. Their How AI Works course teaches you how to build a functioning language model from

49
00:03:15,060 --> 00:03:19,840
scratch, and lets you experiment with things like feature vectors to edit facial expressions and

50
00:03:19,840 --> 00:03:24,880
images. This hands-on approach to learning helps you master challenging concepts over time, and is

51
00:03:24,880 --> 00:03:26,800
proven to be six times more effective than the other. So if you're a visual learner, you should

52
00:03:26,820 --> 00:03:32,500
definitely try Brilliant. Try everything Brilliant has to offer for free by visiting brilliant.org

53
00:03:32,500 --> 00:03:37,860
slash fireship, or scan the QR code on screen to get 20% off their premium annual subscription,

54
00:03:38,100 --> 00:03:41,240
which gives you unlimited daily access to everything on Brilliant.

55
00:03:41,480 --> 00:03:45,200
This has been The Code Report, thanks for watching, and I will see you in the next one.

