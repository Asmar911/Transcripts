A few days ago, image editing changed forever. Google released Gemini Flash 2.5 image, coincidentally, with the same nickname my ex-girlfriend gave me Nano Banana. That has everyone buy inputs on Adobe, because Photoshop is officially dead. Instead of learning how to use all these antique tools, you can now just prompt Nano Banana for changes, and it's able to deliver any photo alterations you can imagine. And most importantly, while maintaining the consistency of the original image. If you're an animator or graphic designer, this can unlock massive productivity gains. Like if you wanted to steal some meat canyon art and make it do something else, you can now accomplish that with a single prompt. No talent, necessary. Google is finally back to its roots building cool stuff, and Flash 2.5 is a tool that makes stable diffusion look like Microsoft's paint. In today's video, we'll take a look at all of its capabilities and find out if our Adobe puts will actually print. It is August 29th, 2025, and you are watching the code report. Not only is Nano Banana an exceptional image model that's already at the top of the L.M. Arena leaderboard, but it's also extremely fast and affordable, costing only 3.9 cents per image via the API. And hypothetically, Google is also trained in even more powerful Grondavenan app, but it's unlikely the common man will ever get access to it. The upgrade that most people are talking about, though, is character consistency. If you start with an image of a person or pet, for example, the model can blend it with a different image or make minor changes to it without noticeably altering the original character. Or multiple characters and objects, like this guy did by blending 13 different images together. That means if you want to link to and headshot of yourself wearing a nice suit, but can't afford to buy an actual suit, Nano Banana has you covered. In addition, if you work for the shadow government, it can be used to implement Mandela effects, like removing the cornacopia from the fruit of the loom logo. That's cool, but if you're wanna be game developer, one of the main showstoppers is the insane amount of time it takes to build up a collection of good-looking assets for all your characters and animations. Well, now, if you start with a base character, you can prompt all the different positions required for an animation. Or better yet, just have Gemini generate an entire sprite for you with all of them in a single prompt. They keep in mind though, if you go this route, you'll have to disclose any AI assets used when you publish on Steam. And you can't lie about it because anything generated with Google has an invisible watermark called SynthID. What's kind of crazy about this model though is that it also has an understanding of the real world. Like if you point to a spot on Google Maps and ask what a person would see there, it can generate a realistic photo. Or if you're a visual learner, you can sketch with it step by step. Like you could use the sketch tool to map out your AWS infrastructure. It's also pretty decent handling text, so you can easily turn your images into lame Instagram ads or memes. But it's still not perfect, so now let's talk about the bad stuff. As you can see in my ad here, it has a tendency to add extra characters to certain words. In addition, I found that it often didn't follow my prompt exactly and just kind of did its own thing. Or in many cases, it just ignored the prompt and did nothing at all. And I think even the character consistency is a bit overhyped. I tried it on a bunch of different images of real humans, and it still has that obvious AI uncanny valley look to it. And finally, as expected, as a Google product, it's highly censored trying to generate anything that's not safe for work is not going to happen. But the best way to get the most out of these AI tools is to learn how they work under the hood. And you can do that for free with brilliant the sponsor of today's video. They're how AI workscores teaches you how to build a functioning language model from scratch, and lets you experiment with things like feature vectors to edit facial expressions and images. This hands-on approach to learning helps you master challenging concepts over time. And is proven to be six times more effective than watching video lectures. Try everything brilliant has to offer for free by visiting brilliant.org slash fire ship or scan the QR code on screen to get 20% off that are premium annual subscription, which gives you unlimited daily access to everything on brilliant. This has been the code report. Thanks for watching, and I will see you in the next one.